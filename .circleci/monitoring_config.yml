# Monitoring and observability setup for FauxDB
version: 2.1

orbs:
  prometheus: prometheus/prometheus@0.16.0
  grafana: grafana/grafana@1.0.0

executors:
  monitoring-executor:
    docker:
      - image: cimg/base:2024.02
    resource_class: small

commands:
  setup_monitoring:
    steps:
      - run:
          name: Install monitoring tools
          command: |
            # Install kubectl
            curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x kubectl && sudo mv kubectl /usr/local/bin/
            
            # Install helm
            curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

jobs:
  setup_prometheus:
    executor: monitoring-executor
    steps:
      - checkout
      - setup_monitoring
      
      - run:
          name: Deploy Prometheus stack
          command: |
            # Add Prometheus Helm repository
            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
            helm repo update
            
            # Create monitoring namespace
            kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
            
            # Create Prometheus values file
            cat > prometheus-values.yaml << 'EOF'
            server:
              global:
                scrape_interval: 15s
                evaluation_interval: 15s
              
              persistentVolume:
                size: 50Gi
                storageClass: gp2
              
              retention: "15d"
              
              configMapOverrides:
                prometheus.yml: |
                  global:
                    scrape_interval: 15s
                    evaluation_interval: 15s
                  
                  rule_files:
                    - "fauxdb_rules.yml"
                  
                  scrape_configs:
                    - job_name: 'fauxdb'
                      static_configs:
                        - targets: ['fauxdb-service.fauxdb-staging:8080', 'fauxdb-service.fauxdb-production:8080']
                      metrics_path: /metrics
                      scrape_interval: 10s
                    
                    - job_name: 'postgresql'
                      static_configs:
                        - targets: ['postgres-exporter:9187']
                      scrape_interval: 30s
                    
                    - job_name: 'kubernetes-pods'
                      kubernetes_sd_configs:
                        - role: pod
                      relabel_configs:
                        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                          action: keep
                          regex: true
            
            alertmanager:
              enabled: true
              persistentVolume:
                size: 10Gi
                storageClass: gp2
              
              config:
                global:
                  smtp_smarthost: 'localhost:587'
                  smtp_from: 'alerts@fauxdb.com'
                
                route:
                  group_by: ['alertname']
                  group_wait: 10s
                  group_interval: 10s
                  repeat_interval: 1h
                  receiver: 'fauxdb-team'
                
                receivers:
                  - name: 'fauxdb-team'
                    email_configs:
                      - to: 'team@fauxdb.com'
                        subject: 'FauxDB Alert: {{ .GroupLabels.alertname }}'
                        body: |
                          {{ range .Alerts }}
                          Alert: {{ .Annotations.summary }}
                          Description: {{ .Annotations.description }}
                          {{ end }}
            
            nodeExporter:
              enabled: true
            
            kubeStateMetrics:
              enabled: true
            EOF
            
            # Deploy Prometheus
            helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
              --namespace monitoring \
              --values prometheus-values.yaml \
              --wait --timeout=600s

      - run:
          name: Create FauxDB alerting rules
          command: |
            cat > fauxdb-alerts.yaml << 'EOF'
            apiVersion: monitoring.coreos.com/v1
            kind: PrometheusRule
            metadata:
              name: fauxdb-alerts
              namespace: monitoring
              labels:
                app: fauxdb
                prometheus: kube-prometheus
                role: alert-rules
            spec:
              groups:
                - name: fauxdb.rules
                  rules:
                    - alert: FauxDBDown
                      expr: up{job="fauxdb"} == 0
                      for: 1m
                      labels:
                        severity: critical
                      annotations:
                        summary: "FauxDB instance is down"
                        description: "FauxDB instance {{ $labels.instance }} has been down for more than 1 minute."
                    
                    - alert: FauxDBHighLatency
                      expr: histogram_quantile(0.95, rate(fauxdb_request_duration_seconds_bucket[5m])) > 0.5
                      for: 5m
                      labels:
                        severity: warning
                      annotations:
                        summary: "High latency on FauxDB"
                        description: "95th percentile latency is {{ $value }}s on {{ $labels.instance }}"
                    
                    - alert: FauxDBHighErrorRate
                      expr: rate(fauxdb_requests_total{status=~"5.."}[5m]) / rate(fauxdb_requests_total[5m]) > 0.1
                      for: 5m
                      labels:
                        severity: critical
                      annotations:
                        summary: "High error rate on FauxDB"
                        description: "Error rate is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
                    
                    - alert: FauxDBHighMemoryUsage
                      expr: (fauxdb_memory_usage_bytes / fauxdb_memory_limit_bytes) > 0.9
                      for: 5m
                      labels:
                        severity: warning
                      annotations:
                        summary: "High memory usage on FauxDB"
                        description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
                    
                    - alert: PostgreSQLConnectionPoolExhausted
                      expr: fauxdb_postgresql_connections_active / fauxdb_postgresql_connections_max > 0.9
                      for: 2m
                      labels:
                        severity: warning
                      annotations:
                        summary: "PostgreSQL connection pool nearly exhausted"
                        description: "Connection pool usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
            EOF
            
            kubectl apply -f fauxdb-alerts.yaml

  setup_grafana:
    executor: monitoring-executor
    steps:
      - checkout
      - setup_monitoring
      
      - run:
          name: Deploy Grafana dashboards
          command: |
            # Create Grafana dashboard ConfigMap
            cat > fauxdb-dashboard.json << 'EOF'
            {
              "dashboard": {
                "id": null,
                "title": "FauxDB Monitoring",
                "tags": ["fauxdb"],
                "style": "dark",
                "timezone": "browser",
                "panels": [
                  {
                    "id": 1,
                    "title": "Request Rate",
                    "type": "graph",
                    "targets": [
                      {
                        "expr": "rate(fauxdb_requests_total[5m])",
                        "legendFormat": "{{ instance }}"
                      }
                    ],
                    "xAxis": {"show": true},
                    "yAxes": [{"unit": "reqps"}],
                    "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
                  },
                  {
                    "id": 2,
                    "title": "Response Time",
                    "type": "graph",
                    "targets": [
                      {
                        "expr": "histogram_quantile(0.95, rate(fauxdb_request_duration_seconds_bucket[5m]))",
                        "legendFormat": "95th percentile"
                      },
                      {
                        "expr": "histogram_quantile(0.50, rate(fauxdb_request_duration_seconds_bucket[5m]))",
                        "legendFormat": "50th percentile"
                      }
                    ],
                    "yAxes": [{"unit": "s"}],
                    "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
                  },
                  {
                    "id": 3,
                    "title": "Error Rate",
                    "type": "singlestat",
                    "targets": [
                      {
                        "expr": "rate(fauxdb_requests_total{status=~\"5..\"}[5m]) / rate(fauxdb_requests_total[5m])",
                        "legendFormat": "Error Rate"
                      }
                    ],
                    "valueName": "current",
                    "format": "percentunit",
                    "colorBackground": true,
                    "thresholds": "0.01,0.05",
                    "colors": ["#299c46", "#e5ac0e", "#d44a3a"],
                    "gridPos": {"h": 4, "w": 6, "x": 0, "y": 8}
                  },
                  {
                    "id": 4,
                    "title": "Active Connections",
                    "type": "singlestat",
                    "targets": [
                      {
                        "expr": "fauxdb_active_connections",
                        "legendFormat": "Active Connections"
                      }
                    ],
                    "gridPos": {"h": 4, "w": 6, "x": 6, "y": 8}
                  },
                  {
                    "id": 5,
                    "title": "Memory Usage",
                    "type": "graph",
                    "targets": [
                      {
                        "expr": "fauxdb_memory_usage_bytes",
                        "legendFormat": "{{ instance }}"
                      }
                    ],
                    "yAxes": [{"unit": "bytes"}],
                    "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
                  },
                  {
                    "id": 6,
                    "title": "PostgreSQL Connections",
                    "type": "graph",
                    "targets": [
                      {
                        "expr": "fauxdb_postgresql_connections_active",
                        "legendFormat": "Active"
                      },
                      {
                        "expr": "fauxdb_postgresql_connections_idle",
                        "legendFormat": "Idle"
                      },
                      {
                        "expr": "fauxdb_postgresql_connections_max",
                        "legendFormat": "Max"
                      }
                    ],
                    "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
                  }
                ],
                "time": {"from": "now-1h", "to": "now"},
                "refresh": "30s"
              }
            }
            EOF
            
            # Create ConfigMap for dashboard
            kubectl create configmap fauxdb-dashboard \
              --from-file=fauxdb-dashboard.json \
              --namespace monitoring \
              -o yaml --dry-run=client | kubectl apply -f -

  setup_logging:
    executor: monitoring-executor
    steps:
      - checkout
      - setup_monitoring
      
      - run:
          name: Deploy ELK stack
          command: |
            # Add Elastic Helm repository
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            # Deploy Elasticsearch
            cat > elasticsearch-values.yaml << 'EOF'
            replicas: 3
            minimumMasterNodes: 2
            
            esConfig:
              elasticsearch.yml: |
                cluster.name: "fauxdb-logs"
                network.host: 0.0.0.0
                discovery.zen.minimum_master_nodes: 2
                discovery.zen.ping.unicast.hosts: elasticsearch-master-headless
            
            resources:
              requests:
                cpu: "100m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "2Gi"
            
            volumeClaimTemplate:
              storageClassName: gp2
              resources:
                requests:
                  storage: 30Gi
            EOF
            
            helm upgrade --install elasticsearch elastic/elasticsearch \
              --namespace monitoring \
              --values elasticsearch-values.yaml \
              --wait --timeout=600s
            
            # Deploy Kibana
            cat > kibana-values.yaml << 'EOF'
            elasticsearchHosts: "http://elasticsearch-master:9200"
            
            ingress:
              enabled: true
              className: "nginx"
              hosts:
                - host: kibana.fauxdb.com
                  paths:
                    - path: /
                      pathType: Prefix
            
            resources:
              requests:
                cpu: "100m"
                memory: "512Mi"
              limits:
                cpu: "1000m"
                memory: "1Gi"
            EOF
            
            helm upgrade --install kibana elastic/kibana \
              --namespace monitoring \
              --values kibana-values.yaml \
              --wait --timeout=300s
            
            # Deploy Filebeat for log collection
            cat > filebeat-values.yaml << 'EOF'
            daemonset:
              enabled: true
            
            filebeatConfig:
              filebeat.yml: |
                filebeat.inputs:
                - type: container
                  paths:
                    - /var/log/containers/*fauxdb*.log
                  processors:
                  - add_kubernetes_metadata:
                      host: ${NODE_NAME}
                      matchers:
                      - logs_path:
                          logs_path: "/var/log/containers/"
                
                output.elasticsearch:
                  host: '${NODE_NAME}'
                  hosts: '${ELASTICSEARCH_HOSTS:elasticsearch-master:9200}'
                  index: "fauxdb-logs-%{+yyyy.MM.dd}"
                
                setup.template.name: "fauxdb-logs"
                setup.template.pattern: "fauxdb-logs-*"
            EOF
            
            helm upgrade --install filebeat elastic/filebeat \
              --namespace monitoring \
              --values filebeat-values.yaml \
              --wait --timeout=300s

workflows:
  monitoring_setup:
    jobs:
      - setup_prometheus:
          filters:
            branches:
              only: 
                - main
                - develop
      
      - setup_grafana:
          requires:
            - setup_prometheus
          filters:
            branches:
              only: 
                - main
                - develop
      
      - setup_logging:
          filters:
            branches:
              only: 
                - main
                - develop
